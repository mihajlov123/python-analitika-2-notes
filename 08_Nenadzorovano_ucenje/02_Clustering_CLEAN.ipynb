{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c197aaa",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b418d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bc7ec",
   "metadata": {},
   "source": [
    "## What Is Clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e6147",
   "metadata": {},
   "source": [
    "**Clustering is the task of partitioning the dataset into groups, called clusters.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847022e",
   "metadata": {},
   "source": [
    "**Meaningful clusters** expand domain knowledge. For example, in the medical field, researchers applied clustering to gene expression experiments. The clustering results identified groups of patients who respond differently to medical treatments.\n",
    "\n",
    "**Useful clusters**, on the other hand, serve as an intermediate step in a data pipeline. For example, businesses use clustering for customer segmentation. The clustering results segment customers into groups with similar purchase histories, which businesses can then use to create targeted advertising campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74539afd",
   "metadata": {},
   "source": [
    "## Overview of Clustering Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0019f85",
   "metadata": {},
   "source": [
    "<img loading=\"lazy\" class=\"img-fluid mx-auto d-block \" src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf49eab",
   "metadata": {},
   "source": [
    "<table class=\"colwidths-given docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 15%\">\n",
    "<col style=\"width: 16%\">\n",
    "<col style=\"width: 20%\">\n",
    "<col style=\"width: 27%\">\n",
    "<col style=\"width: 22%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Method name</p></th>\n",
    "<th class=\"head\"><p>Parameters</p></th>\n",
    "<th class=\"head\"><p>Scalability</p></th>\n",
    "<th class=\"head\"><p>Usecase</p></th>\n",
    "<th class=\"head\"><p>Geometry (metric used)</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#k-means\"><span class=\"std std-ref\">K-Means</span></a></p></td>\n",
    "<td><p>number of clusters</p></td>\n",
    "<td><p>Very large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code>, medium <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code> with\n",
    "<a class=\"reference internal\" href=\"#mini-batch-kmeans\"><span class=\"std std-ref\">MiniBatch code</span></a></p></td>\n",
    "<td><p>General-purpose, even cluster size, flat geometry,\n",
    "not too many clusters, inductive</p></td>\n",
    "<td><p>Distances between points</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#affinity-propagation\"><span class=\"std std-ref\">Affinity propagation</span></a></p></td>\n",
    "<td><p>damping, sample preference</p></td>\n",
    "<td><p>Not scalable with n_samples</p></td>\n",
    "<td><p>Many clusters, uneven cluster size, non-flat geometry, inductive</p></td>\n",
    "<td><p>Graph distance (e.g. nearest-neighbor graph)</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#mean-shift\"><span class=\"std std-ref\">Mean-shift</span></a></p></td>\n",
    "<td><p>bandwidth</p></td>\n",
    "<td><p>Not scalable with <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code></p></td>\n",
    "<td><p>Many clusters, uneven cluster size, non-flat geometry, inductive</p></td>\n",
    "<td><p>Distances between points</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#spectral-clustering\"><span class=\"std std-ref\">Spectral clustering</span></a></p></td>\n",
    "<td><p>number of clusters</p></td>\n",
    "<td><p>Medium <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code>, small <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code></p></td>\n",
    "<td><p>Few clusters, even cluster size, non-flat geometry, transductive</p></td>\n",
    "<td><p>Graph distance (e.g. nearest-neighbor graph)</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#hierarchical-clustering\"><span class=\"std std-ref\">Ward hierarchical clustering</span></a></p></td>\n",
    "<td><p>number of clusters or distance threshold</p></td>\n",
    "<td><p>Large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code></p></td>\n",
    "<td><p>Many clusters, possibly connectivity constraints, transductive</p></td>\n",
    "<td><p>Distances between points</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#hierarchical-clustering\"><span class=\"std std-ref\">Agglomerative clustering</span></a></p></td>\n",
    "<td><p>number of clusters or distance threshold, linkage type, distance</p></td>\n",
    "<td><p>Large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code></p></td>\n",
    "<td><p>Many clusters, possibly connectivity constraints, non Euclidean\n",
    "distances, transductive</p></td>\n",
    "<td><p>Any pairwise distance</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dbscan\"><span class=\"std std-ref\">DBSCAN</span></a></p></td>\n",
    "<td><p>neighborhood size</p></td>\n",
    "<td><p>Very large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code>, medium <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code></p></td>\n",
    "<td><p>Non-flat geometry, uneven cluster sizes, outlier removal,\n",
    "transductive</p></td>\n",
    "<td><p>Distances between nearest points</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#optics\"><span class=\"std std-ref\">OPTICS</span></a></p></td>\n",
    "<td><p>minimum cluster membership</p></td>\n",
    "<td><p>Very large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code>, large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code></p></td>\n",
    "<td><p>Non-flat geometry, uneven cluster sizes, variable cluster density,\n",
    "outlier removal, transductive</p></td>\n",
    "<td><p>Distances between points</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"mixture.html#mixture\"><span class=\"std std-ref\">Gaussian mixtures</span></a></p></td>\n",
    "<td><p>many</p></td>\n",
    "<td><p>Not scalable</p></td>\n",
    "<td><p>Flat geometry, good for density estimation, inductive</p></td>\n",
    "<td><p>Mahalanobis distances to  centers</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#birch\"><span class=\"std std-ref\">BIRCH</span></a></p></td>\n",
    "<td><p>branching factor, threshold, optional global clusterer.</p></td>\n",
    "<td><p>Large <code class=\"docutils literal notranslate\"><span class=\"pre\">n_clusters</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">n_samples</span></code></p></td>\n",
    "<td><p>Large dataset, outlier removal, data reduction, inductive</p></td>\n",
    "<td><p>Euclidean distance between points</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c721d",
   "metadata": {},
   "source": [
    "<img src=\"images/flat-nonflat.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e5847",
   "metadata": {},
   "source": [
    "### Partitional Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d49a0",
   "metadata": {},
   "source": [
    "<section class=\"section3\" id=\"partitional-clustering\">\n",
    "<p><strong>Partitional clustering</strong> divides data objects into nonoverlapping groups. In other words, no object can be a member of more than one cluster, and every cluster must have at least one object. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677ff05",
   "metadata": {},
   "source": [
    "<img src=\"https://microsoft.github.io/ML-For-Beginners/5-Clustering/1-Visualize/./images/centroid.png\" data-origin=\"./images/centroid.png\" alt=\"Centroid clustering Infographic\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e463eee",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2280d",
   "metadata": {},
   "source": [
    "<section class=\"section3\" id=\"hierarchical-clustering\">\n",
    "<p><strong>Hierarchical clustering</strong> determines cluster assignments by building a hierarchy. This is implemented by either a bottom-up or a top-down approach:</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a561ad3",
   "metadata": {},
   "source": [
    "<img src=\"https://microsoft.github.io/ML-For-Beginners/5-Clustering/1-Visualize/./images/hierarchical.png\" data-origin=\"./images/hierarchical.png\" alt=\"Hierarchical clustering Infographic\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a657af",
   "metadata": {},
   "source": [
    "### Density-Based Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158166e",
   "metadata": {},
   "source": [
    "<section class=\"section3\" id=\"density-based-clustering\">\n",
    "<p><strong>Density-based clustering</strong> determines cluster assignments based on the density of data points in a region. Clusters are assigned where there are high densities of data points separated by low-density regions. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d199da",
   "metadata": {},
   "source": [
    "## k-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f46272",
   "metadata": {},
   "source": [
    "- **k-means clustering** is one of the **simplest and most commonly used** clustering algorithms.\n",
    "\n",
    "- It tries to find cluster centers that are representative of certain regions of the data. \n",
    "- Conventional k-means requires only a few steps. **The first step is to randomly select k centroids, where k is equal to the number of clusters you choose**. \n",
    "- Centroids are data points representing the center of a cluster.\n",
    "- Then the algorithm alternates between two steps: \n",
    "    1. assigning each data point to the closest cluster center\n",
    "    2. then setting each cluster center as the mean of the data points that are assigned to it. \n",
    "\n",
    "\n",
    "- The algorithm is finished when the assignment of instances to clusters no longer changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072f40e",
   "metadata": {},
   "source": [
    "<img loading=\"lazy\" class=\"img-fluid mx-auto d-block \" src=\"https://files.realpython.com/media/kmeans-algorithm.a94498a7ecd2.png\" width=\"1186\" height=\"332\" srcset=\"https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/kmeans-algorithm.a94498a7ecd2.png&amp;w=296&amp;sig=efa46cf1bfa03d5dac763ccfd1e1ed573afdc86a 296w, https://robocrop.realpython.net/?url=https%3A//files.realpython.com/media/kmeans-algorithm.a94498a7ecd2.png&amp;w=593&amp;sig=5d5c01463b76abb809eb35ae90ca916bb34d2bb7 593w, https://files.realpython.com/media/kmeans-algorithm.a94498a7ecd2.png 1186w\" sizes=\"75vw\" alt=\"k means algorithm\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8fc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_kmeans import plot_kmeans_algorithm\n",
    "\n",
    "plot_kmeans_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_kmeans import plot_kmeans_boundaries\n",
    "\n",
    "plot_kmeans_boundaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# generate synthetic two-dimensional data\n",
    "X, y = make_blobs(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07043222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the clustering model\n",
    "kmeans = KMeans(n_clusters=3, n_init=10)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cluster memberships:\\n{kmeans.labels_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da326a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c842059",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_helpers import discrete_scatter\n",
    "\n",
    "discrete_scatter(X[:, 0], X[:, 1], kmeans.labels_, markers='o')\n",
    "discrete_scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2], markers='o', markeredgewidth=2, c='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# using two cluster centers:\n",
    "kmeans = KMeans(n_clusters=2, n_init=10)\n",
    "kmeans.fit(X)\n",
    "assignments = kmeans.labels_\n",
    "discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[0])\n",
    "\n",
    "# using five cluster centers:\n",
    "kmeans = KMeans(n_clusters=5, n_init=10)\n",
    "kmeans.fit(X)\n",
    "assignments = kmeans.labels_\n",
    "discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431a1bd",
   "metadata": {},
   "source": [
    "### Failure cases of k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfae4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_varied, y_varied = make_blobs(n_samples=200, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
    "\n",
    "y_pred = KMeans(n_clusters=3, random_state=0, n_init=10).fit_predict(X_varied)\n",
    "\n",
    "discrete_scatter(X_varied[:, 0], X_varied[:, 1], y_pred)\n",
    "\n",
    "plt.legend([\"cluster 0\", \"cluster 1\", \"cluster 2\"], loc='best')\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_helpers import cm3\n",
    "\n",
    "# generate some random cluster data\n",
    "X, y = make_blobs(random_state=170, n_samples=600)\n",
    "rng = np.random.RandomState(74)\n",
    "\n",
    "# transform the data to be stretched\n",
    "transformation = rng.normal(size=(2, 2))\n",
    "X = np.dot(X, transformation)\n",
    "\n",
    "# cluster the data into three clusters\n",
    "kmeans = KMeans(n_clusters=3, n_init=10)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "# plot the cluster assignments and cluster centers\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=cm3)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='^', c='y', s=100, linewidth=2, cmap=cm3)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic two_moons data\n",
    "from sklearn.datasets import make_moons\n",
    "from helpers.plot_helpers import cm2\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# cluster the data into two clusters\n",
    "kmeans = KMeans(n_clusters=2, n_init=10)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "# plot the cluster assignments and cluster centers\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=cm2, s=60)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='^', c=\"y\", s=100, linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769bfad",
   "metadata": {},
   "source": [
    "### Understanding the K-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740cf3e3",
   "metadata": {},
   "source": [
    "<img loading=\"lazy\" class=\"img-fluid mx-auto d-block w-50\" src=\"https://files.realpython.com/media/centroids_iterations.247379590275.gif\" width=\"576\" height=\"576\" srcset=\"https://files.realpython.com/media/centroids_iterations.247379590275.gif 144w, https://files.realpython.com/media/centroids_iterations.247379590275.gif 288w, https://files.realpython.com/media/centroids_iterations.247379590275.gif 576w\" sizes=\"75vw\" alt=\"k means centroids iterations\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70cef56",
   "metadata": {},
   "source": [
    "### Choosing the Appropriate Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd68f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "features, true_labels = make_blobs(n_samples=200, centers=3, cluster_std=2.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_scatter(features[:, 0], features[:, 1], true_labels) # v realnosti nimamo pravih vrednosti\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750075ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e72174",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59407190",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(    \n",
    "    init=\"random\",\n",
    "    n_clusters=3,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c58bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2223205",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kmeans.predict(scaled_features)\n",
    "discrete_scatter(scaled_features[:, 0], scaled_features[:, 1], y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4634679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lowest SSE value\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb99425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final locations of the centroid\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of iterations required to converge\n",
    "kmeans.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd55f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The elbow method\n",
    "kmeans_kwargs = {\"init\": \"random\", \"n_init\": 10, \"max_iter\": 300,\"random_state\": 42,}\n",
    "\n",
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(scaled_features)\n",
    "    sse.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69059b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(1, 11), sse)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "kl = KneeLocator(range(1, 11), sse, curve=\"convex\", direction=\"decreasing\")\n",
    "kl.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# A list holds the silhouette coefficients for each k\n",
    "silhouette_coefficients = []\n",
    "\n",
    "# Notice you start at 2 clusters for silhouette coefficient\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(scaled_features)\n",
    "    score = silhouette_score(scaled_features, kmeans.labels_)\n",
    "    silhouette_coefficients.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, 11), silhouette_coefficients)\n",
    "plt.xticks(range(2, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287038d",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4347c",
   "metadata": {},
   "source": [
    "**Agglomerative clustering** refers to a collection of clustering algorithms that all build\n",
    "upon the same principles: \n",
    "1. the algorithm starts by declaring each point its own cluster\n",
    "2. then merges the two most similar clusters until some stopping criterion is satisfied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_agglomerative import plot_agglomerative_algorithm\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plot_agglomerative_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1536a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X, y = make_blobs(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "assignment = agg.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_scatter(X[:, 0], X[:, 1], assignment)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f0e68",
   "metadata": {},
   "source": [
    "### Hierarchical clustering and dendrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_agglomerative import plot_agglomerative\n",
    "\n",
    "plot_agglomerative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e323d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dendrogram function and the ward clustering function from SciPy\n",
    "from scipy.cluster.hierarchy import dendrogram, ward\n",
    "\n",
    "X, y = make_blobs(random_state=0, n_samples=12)\n",
    "\n",
    "# Apply the ward clustering to the data array X\n",
    "# The SciPy ward function returns an array that specifies the distances\n",
    "# bridged when performing agglomerative clustering\n",
    "linkage_array = ward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675714d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the dendrogram for the linkage_array containing the distances\n",
    "# between clusters\n",
    "dendrogram(linkage_array)\n",
    "\n",
    "# Mark the cuts in the tree that signify two or three clusters\n",
    "ax = plt.gca()\n",
    "bounds = ax.get_xbound()\n",
    "ax.plot(bounds, [7.25, 7.25], '--', c='k')\n",
    "ax.plot(bounds, [4, 4], '--', c='k')\n",
    "ax.text(bounds[1], 7.25, ' two clusters', va='center', fontdict={'size': 15})\n",
    "ax.text(bounds[1], 4, ' three clusters', va='center', fontdict={'size': 15})\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Cluster distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a49734",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_blobs(random_state=0, n_samples=12)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "print(f\"Cluster memberships:\\n{clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c325c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_dbscan import plot_dbscan\n",
    "\n",
    "plot_dbscan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "from helpers.plot_helpers import cm2\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# rescale the data to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# plot the cluster assignments\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=cm2, s=60)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549edb47",
   "metadata": {},
   "source": [
    "## Comparing and Evaluating Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbaf0e2",
   "metadata": {},
   "source": [
    "### Evaluating clustering with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86725cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# rescale the data to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "# make a list of algorithms to use\n",
    "algorithms = [KMeans(n_clusters=2, n_init=10), AgglomerativeClustering(n_clusters=2), DBSCAN()]\n",
    "\n",
    "# create a random cluster assignment for reference\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "random_clusters = random_state.randint(low=0, high=2, size=len(X))\n",
    "\n",
    "# plot random assignment\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters, cmap=cm3, s=60)\n",
    "axes[0].set_title(f\"Random assignment - ARI: {adjusted_rand_score(y, random_clusters):.2f}\\n \\\n",
    "Random assignment - NMI - {normalized_mutual_info_score(y, random_clusters):.2f}\")\n",
    "\n",
    "for ax, algorithm in zip(axes[1:], algorithms):\n",
    "    # plot the cluster assignments and cluster centers\n",
    "    clusters = algorithm.fit_predict(X_scaled)\n",
    "    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=cm3, s=60)\n",
    "    ax.set_title(f\"{algorithm.__class__.__name__} - ARI: {adjusted_rand_score(y, clusters):.2f}\\n \\\n",
    "{algorithm.__class__.__name__} - NMI - {normalized_mutual_info_score(y, clusters):.2f}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# these two labelings of points correspond to the same clustering\n",
    "clusters1 = [0, 0, 1, 1, 0]\n",
    "clusters2 = [1, 1, 0, 0, 1]\n",
    "\n",
    "# accuracy is zero, as none of the labels are the same\n",
    "print(f\"Accuracy: {accuracy_score(clusters1, clusters2):.2f}\")\n",
    "\n",
    "# adjusted rand score is 1, as the clustering is exactly the same\n",
    "print(f\"ARI: {adjusted_rand_score(clusters1, clusters2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b4401",
   "metadata": {},
   "source": [
    "### Evaluating clustering without ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# rescale the data to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "# create a random cluster assignment for reference\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "random_clusters = random_state.randint(low=0, high=2, size=len(X))\n",
    "\n",
    "# plot random assignment\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters, cmap=cm3, s=60)\n",
    "axes[0].set_title(\"Random assignment: {:.2f}\".format(silhouette_score(X_scaled, random_clusters)))\n",
    "\n",
    "algorithms = [KMeans(n_clusters=2, n_init=10), AgglomerativeClustering(n_clusters=2), DBSCAN()]\n",
    "\n",
    "for ax, algorithm in zip(axes[1:], algorithms):\n",
    "    clusters = algorithm.fit_predict(X_scaled)\n",
    "    # plot the cluster assignments and cluster centers\n",
    "    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=cm3, s=60)\n",
    "    ax.set_title(f\"{algorithm.__class__.__name__} : {silhouette_score(X_scaled, clusters):.2f}\".format())\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d572939",
   "metadata": {},
   "source": [
    "## Comparing algorithms on the faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)\n",
    "image_shape = people.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"people.images.shape: {people.images.shape}\")\n",
    "print(f\"Number of classes: {len(people.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9149dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(people.target.shape, dtype=bool)\n",
    "\n",
    "for target in np.unique(people.target):\n",
    "    mask[np.where(people.target == target)[0][:50]] = 1\n",
    "    \n",
    "X_people = people.data[mask]\n",
    "y_people = people.target[mask]\n",
    "\n",
    "# scale the grayscale values to be between 0 and 1\n",
    "# instead of 0 and 255 for better numeric stability\n",
    "X_people = X_people / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract eigenfaces from lfw data and transform data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100, whiten=True, random_state=0)\n",
    "\n",
    "pca.fit_transform(X_people)\n",
    "X_pca = pca.transform(X_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d7cac",
   "metadata": {},
   "source": [
    "### Analyzing the faces dataset with DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply DBSCAN with default parameters\n",
    "dbscan = DBSCAN()\n",
    "labels = dbscan.fit_predict(X_pca)\n",
    "\n",
    "print(f\"Unique labels: {np.unique(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(min_samples=3)\n",
    "labels = dbscan.fit_predict(X_pca)\n",
    "\n",
    "print(f\"Unique labels: {np.unique(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(min_samples=3, eps=15)\n",
    "labels = dbscan.fit_predict(X_pca)\n",
    "\n",
    "print(f\"Unique labels: {np.unique(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of points in all clusters and noise.\n",
    "# bincount doesn't allow negative numbers, so we need to add 1.\n",
    "# The first number in the result corresponds to noise points.\n",
    "print(f\"Number of points per cluster: {np.bincount(labels + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = X_people[labels==-1]\n",
    "\n",
    "fig, axes = plt.subplots(3, 9, subplot_kw={'xticks': (), 'yticks': ()}, figsize=(12, 4))\n",
    "\n",
    "for image, ax in zip(noise, axes.ravel()):\n",
    "    ax.imshow(image.reshape(image_shape), vmin=0, vmax=1)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbae5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [1, 3, 5, 7, 9, 11, 13]:\n",
    "    print(f\"\\neps={eps}\")\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=3)\n",
    "    labels = dbscan.fit_predict(X_pca)\n",
    "    print(f\"Clusters present: {np.unique(labels)}\")\n",
    "    print(f\"Cluster sizes: {np.bincount(labels + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(min_samples=3, eps=7)\n",
    "labels = dbscan.fit_predict(X_pca)\n",
    "\n",
    "for cluster in range(max(labels) + 1):\n",
    "    mask = labels == cluster\n",
    "    n_images = np.sum(mask)\n",
    "    fig, axes = plt.subplots(1, n_images, figsize=(n_images * 1.5, 4), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "    for image, label, ax in zip(X_people[mask], y_people[mask], axes):\n",
    "        ax.imshow(image.reshape(image_shape), vmin=0, vmax=1)\n",
    "        ax.set_title(people.target_names[label].split()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad8cfc",
   "metadata": {},
   "source": [
    "### Analyzing the faces dataset with k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87455ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract clusters with k-means\n",
    "km = KMeans(n_clusters=10, random_state=0)\n",
    "labels_km = km.fit_predict(X_pca)\n",
    "print(f\"Cluster sizes k-means: {np.bincount(labels_km)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, subplot_kw={'xticks': (), 'yticks': ()}, figsize=(12, 4))\n",
    "\n",
    "for center, ax in zip(km.cluster_centers_, axes.ravel()):\n",
    "    ax.imshow(pca.inverse_transform(center).reshape(image_shape), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d603c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot_kmeans import plot_kmeans_faces\n",
    "\n",
    "plot_kmeans_faces(km, pca, X_pca, X_people, y_people, people.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1739dcd",
   "metadata": {},
   "source": [
    "### Analyzing the faces dataset with agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract clusters with ward agglomerative clustering\n",
    "agglomerative = AgglomerativeClustering(n_clusters=10)\n",
    "labels_agg = agglomerative.fit_predict(X_pca)\n",
    "\n",
    "print(f\"Cluster sizes agglomerative clustering: {np.bincount(labels_agg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ARI: {adjusted_rand_score(labels_agg, labels_km):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cd1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_array = ward(X_pca)\n",
    "\n",
    "# now we plot the dendrogram for the linkage_array\n",
    "# containing the distances between clusters\n",
    "plt.figure(figsize=(20, 5))\n",
    "dendrogram(linkage_array, p=7, truncate_mode='level', no_labels=True)\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Cluster distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83141af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "for cluster in range(n_clusters):\n",
    "    mask = labels_agg == cluster\n",
    "    fig, axes = plt.subplots(1, 10, subplot_kw={'xticks': (), 'yticks': ()}, figsize=(15, 8))\n",
    "    axes[0].set_ylabel(np.sum(mask))\n",
    "    for image, label, asdf, ax in zip(X_people[mask], y_people[mask], labels_agg[mask], axes):\n",
    "        ax.imshow(image.reshape(image_shape), vmin=0, vmax=1)\n",
    "        ax.set_title(people.target_names[label].split()[-1], fontdict={'fontsize': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract clusters with ward agglomerative clustering\n",
    "agglomerative = AgglomerativeClustering(n_clusters=40)\n",
    "labels_agg = agglomerative.fit_predict(X_pca)\n",
    "print(f\"cluster sizes agglomerative clustering: {np.bincount(labels_agg)}\")\n",
    "\n",
    "n_clusters = 40\n",
    "for cluster in [10, 13, 19, 22, 36]: # hand-picked \"interesting\" clusters\n",
    "    mask = labels_agg == cluster\n",
    "    fig, axes = plt.subplots(1, 15, subplot_kw={'xticks': (), 'yticks': ()}, figsize=(15, 8))\n",
    "    cluster_size = np.sum(mask)\n",
    "    axes[0].set_ylabel(f\"#{cluster}: {cluster_size}\")\n",
    "    for image, label, asdf, ax in zip(X_people[mask], y_people[mask], labels_agg[mask], axes):\n",
    "        ax.imshow(image.reshape(image_shape), vmin=0, vmax=1)\n",
    "        ax.set_title(people.target_names[label].split()[-1], fontdict={'fontsize': 9})\n",
    "    for i in range(cluster_size, 15):\n",
    "        axes[i].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
