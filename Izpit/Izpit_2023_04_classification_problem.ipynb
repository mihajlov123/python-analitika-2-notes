{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Izpit: Analitika 2: Strojno učenje v Python-u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rok oddaje: `TODO!`\n",
    "\n",
    "Cilj: `doseči čim boljšo končno napoved.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za vsa vprašanja smo na voljo.\n",
    "\n",
    "Lahko si pomagate z uporabo gradiv in internetom. Ne pozabite na uradno dokumentacijo.\n",
    "\n",
    "Srečno!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izbirate lahko med dvema nalogama oziroma problemoma:\n",
    "\n",
    "* Klasifikacijski --> Glede na podane karakteristike površja, klasificirajte rastje se tam nahaja\n",
    "* Regresijski --> Napoved cene hiše"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Klasifikacijski\n",
    "\n",
    "Podane imate podatke o _30m x 30m_ območjih divjine/narave in njihovih karakektaristikah.\n",
    "\n",
    "Atributi:\n",
    "* `NadmorskaVisina` (nadmorska višina v metrih)\n",
    "* `StopinjeAzimuth` (azimut kot v stopinjah)\n",
    "* `Naklon` (naklon območja v stopinjah)\n",
    "* `DolzinaDoVode` (najkrajša dolžina do vode na površju v metrih)\n",
    "* `VertikalnaDolzinaDoVode` (vertikalna najkrajša dolžina do vode na površju v metrih)\n",
    "* `DolzinaDoZeleznice` (najkrajša dožina do železnice v metrih)\n",
    "* `HillshadeIndeksOb9h` (hillshade indeks ob 9:00 --> območe vrednosti: [0,255])\n",
    "* `HillshadeIndeksOb12h` (hillshade indeks ob 12:00 --> območe vrednosti: [0,255])\n",
    "* `HillshadeIndeksOb15h` (hillshade indeks ob 15:00 --> območe vrednosti: [0,255])\n",
    "* `DolzinaDoPozarneTocke` (najkrajša dolžina do požarno nevarne/vnetljive točke v metrih)\n",
    "* `Obmocje` (indeks območja v katerem se nahaja ta predel --> območje vrednosti: [1,4])\n",
    "* `TipZemlje` (indeks tipa zemlje na tem območju --> območje vrednosti: [1,40])\n",
    "\n",
    "\n",
    "Ciljni atribut:\n",
    "* `TipRastja` (indeks tipa rastja ki se nahaja na tem območju)\n",
    "\n",
    "Vaša naloga je, da izdelate klasifikacijski model, ki bo čim boljše klasificiral tip rastja, ki se nahaja na nekem območju glede na podane atribute.\n",
    "\n",
    "Za napovedovanje lahko uporabite kakršnekoli metode.\n",
    "\n",
    "Pred samo napovedjo boste morali značilke urediti v obliko, ki bo omogočala napovedovanje tipa rastja.\n",
    "\n",
    "```\n",
    "POZOR: Pazite, da za optimizacijo modela uporabljate validacijske podatke, ki jih naredite z delitvijo train podatkov, že naloženih s spodnjo kodo. Spodnje celice ne spreminjajte, da vsi primerjamo rezultate z istimi testnimi podatki.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"./data/Problem1_tip_narave.csv\",sep=\"\\t\",encoding=\"utf-8\")\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42, shuffle=True)\n",
    "# display(data)\n",
    "# display(train)\n",
    "# display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train in test podatke razdelimo na znacilke in prediktorje za nadaljnjo uporabo\n",
    "y_train = train['TipRastja']\n",
    "X_train = train.drop(columns=[\"TipRastja\"])\n",
    "y_test = test['TipRastja']\n",
    "X_test = test.drop(columns=[\"TipRastja\"])\n",
    "\n",
    "# Pripravimo si skalirane podatke, ki jih uporabljamo v nadaljevanju notebooka\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data study before building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPAZKE\n",
    "# - Ni manjkajočih podatkov, kar pomeni da imputacija ne bo potrebna\n",
    "# - Prav tako opazimo, da so vse značilke tipa float64 (predictor je int). To pomeni, da encoding ni potreben. \n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.describe().transpose())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Porazdelitev vrednosti v značilkah**\n",
    "- Ugotovitev: v primeru uporabe nekaterih modelov (npr: logistična regresija) bi bilo smiselno normalizirati porazdelitve nekaterih značilk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "data.hist(bins=30, figsize=(12,12), density=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobno ugotovimo z uporabo qq-plota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(data.columns), ncols=1, figsize=(6, 30))\n",
    "\n",
    "for i, col in enumerate(data.columns):\n",
    "    ax = axes[i]\n",
    "    stats.probplot(data[col], dist=\"norm\", plot=ax)\n",
    "    ax.set_title(f\"Probability Plot for {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- magnitude spremenljivk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max() - data.min()\n",
    "# magnitude dolocenih spremenljivk se zelo razlikujejo - potrebno skaliranje"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistična regresija"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zaradi večjega števila sample-ov uporabimo metodo 'newton-cholesky'\n",
    "    - `newton-cholesky` is a good choice for n_samples >> n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "traning_scores = {}\n",
    "testing_scores = {}\n",
    "\n",
    "c_values = np.logspace(-3, 9, num=13)\n",
    "\n",
    "for c in c_values:\n",
    "    logreg_diff = LogisticRegression(C=c, solver='newton-cholesky',max_iter=100).fit(X_train_scaled, y_train)\n",
    "    traning_scores[c] = logreg_diff.score(X_train_scaled, y_train)\n",
    "    testing_scores[c] = logreg_diff.score(X_test_scaled, y_test)\n",
    "    \n",
    "plt.plot(traning_scores.keys(), traning_scores.values(), c=\"blue\", label=\"training\")\n",
    "plt.plot(testing_scores.keys(), testing_scores.values(), c=\"red\", label=\"testing\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.show()\n",
    "\n",
    "# display(traning_scores)\n",
    "# display(testing_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "logreg = LogisticRegression(C=10, solver='newton-cholesky',max_iter=10000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = logreg.predict(X_test_scaled)\n",
    "print(f\"Training set score: {logreg.score(X_train_scaled, y_train):.2f}\")\n",
    "print(f\"Test set score: {logreg.score(X_test_scaled, y_test):.2f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklep: Model logistične regresije ni dovolj kompleksen, underfitta za ta primer. Za boljše rezultate bi bilo potrebno linearizirati določene značilke. V nadaljevanju raje poskusimo z drugimi klasifikacijskimi metodami."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNeighbour and Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def get_score(*, model, X_train, X_test, y_train, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"------------- {type(model).__name__} -------------\")\n",
    "    print(f\"Training set score: {model.score(X_train, y_train):.2f}\")\n",
    "    print(f\"Test set score: {model.score(X_test, y_test):.2f}\")\n",
    "    print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "get_score(model=knn, X_train=X_train_scaled, X_test=X_test_scaled, y_train=y_train, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "get_score(model=tree, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest\n",
    "- uporabimo hiperoptimizacijo modela v kombinaciji s cross-validacijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "\n",
    "# forest = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "# forest.fit(X_train, y_train)\n",
    "# get_score(model=forest, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "\n",
    "def objective(trial, X_train, y_train):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 20)\n",
    "    max_depth = int(trial.suggest_float('max_depth', 1, 32, log=True))    \n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)    \n",
    "    return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3).mean()\n",
    "\n",
    "func = lambda trial: objective(trial, X_train, y_train)\n",
    "\n",
    "study = optuna.create_study(direction='maximize') # povemo ali zelimo minimizirati ali maximizirati\n",
    "study.optimize(func, n_trials=100)\n",
    "trial = study.best_trial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results\n",
    "```\n",
    "Accuracy: 0.9461431781759922\n",
    "Best hyperparameters: {'n_estimators': 19, 'max_depth': 31.05729835942615}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study, params=['n_estimators', 'max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne pozabi?\n",
    " - ali je potreben feature engineering\n",
    " - grid search in cross validation\n",
    " - na koncu uporabi metode za oceno uspešnosti modela\n",
    " - uporabi pipeline\n",
    " - zmanjšanje števila značilk?\n",
    " - sklairanje\n",
    " - normalizacija \n",
    " - potrebno je regularizirati model zaradi velikega števila spremenljivk da ne pride do overfittinga"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ecf2b9bec03ffdeedd6f93263319f3fbbf4b32c0dbd57148b9b626b3dfa2bbc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
